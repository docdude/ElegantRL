# TD3 Base Configuration for Alpaca Stock Trading HPO
# Usage: python examples/hpo_alpaca_vecenv.py --config-name=alpaca_td3
# HPO:   python examples/hpo_alpaca_vecenv.py -m --config-name=alpaca_td3

defaults:
  - _self_
  - search_space: td3_space
  - override hydra/sweeper: HyperSMAC

# Agent settings
agent: td3
gpu_id: 0

# Cross-validation methodology
cv_method: holdout  # holdout | wf | cpcv
n_folds: 3          # for wf
n_groups: 5         # for cpcv (N)
n_test_groups: 2    # for cpcv (K)
embargo_pct: 0.01   # cpcv embargo
test_ratio: 0.2     # held-out test fraction
gap_days: 0

# Training settings
seed: 42
break_step: 500000

# Environment settings (fixed)
state_dim: 283
action_dim: 28
max_step: 119  # validation period
num_envs: 96  # Reduced for off-policy

# Hyperparameters (defaults - overridden by search space)
learning_rate: 1e-4
gamma: 0.99
net_arch: "medium"  # small=[64,64], medium=[256,128], large=[512,256]
batch_size: 256
buffer_size: 100000
soft_update_tau: 0.005
horizon_len: 256
repeat_times: 2
clip_grad_norm: 3.0

# TD3 specific
explore_noise_std: 0.1  # Exploration noise
policy_noise_std: 0.2   # Target policy smoothing noise
update_freq: 2          # Delayed policy update
num_ensembles: 8        # Twin critics (can be more)

# VecNormalize settings
use_vec_normalize: true
norm_obs: true
norm_reward: true  # Off-policy: VecNormalize reward normalization provides variance reduction for Q-learning

# HPO settings
cleanup_checkpoints: true

hydra:
  sweeper:
    n_trials: 50
    sweeper_kwargs:
      seeds: [0, 1, 2]
      max_parallelization: 1
      optimizer_kwargs:
        smac_facade:
          _target_: smac.facade.HyperparameterOptimizationFacade
          _partial_: true
          logging_level: 20
        scenario:
          seed: ${seed}
          n_trials: ${hydra.sweeper.n_trials}
          deterministic: false
          n_workers: 1
          output_directory: ${hydra.sweep.dir}
    search_space: ${search_space}
  run:
    dir: outputs/${agent}/${now:%Y-%m-%d_%H-%M-%S}
  sweep:
    dir: outputs/${agent}_sweep/${now:%Y-%m-%d_%H-%M-%S}
