# DDPG Base Configuration for Alpaca Stock Trading HPO
# Usage: python examples/hpo_alpaca_vecenv.py --config-name=alpaca_ddpg
# HPO:   python examples/hpo_alpaca_vecenv.py -m --config-name=alpaca_ddpg
# Note: DDPG is essentially TD3 without twin critics and delayed updates

defaults:
  - _self_
  - search_space: ddpg_space
  - override hydra/sweeper: HyperSMAC

# Agent settings
agent: ddpg
gpu_id: 0

# Cross-validation methodology
cv_method: holdout  # holdout | wf | cpcv
n_folds: 3          # for wf
n_groups: 5         # for cpcv (N)
n_test_groups: 2    # for cpcv (K)
embargo_pct: 0.01   # cpcv embargo
test_ratio: 0.2     # held-out test fraction
gap_days: 0

# Training settings
seed: 42
break_step: 500000

# Environment settings (fixed)
state_dim: 283
action_dim: 28
max_step: 119  # validation period
num_envs: 96

# Hyperparameters (defaults - overridden by search space)
learning_rate: 1e-4
gamma: 0.99
net_arch: "medium"  # small=[64,64], medium=[256,128], large=[512,256]
batch_size: 256
buffer_size: 100000
soft_update_tau: 0.005
horizon_len: 256
repeat_times: 2
clip_grad_norm: 3.0
explore_noise_std: 0.1

# TD3/DDPG specific (DDPG doesn't use update_freq, but search space has it)
policy_noise_std: 0.1
update_freq: 1  # DDPG updates every step (no delay)
num_ensembles: 2

# VecNormalize settings
use_vec_normalize: true
norm_obs: true
norm_reward: false  # Always false â€” env already scales rewards; norm_reward causes critic divergence

# HPO settings
cleanup_checkpoints: true

hydra:
  sweeper:
    n_trials: 50
    sweeper_kwargs:
      seeds: [0, 1, 2]
      max_parallelization: 1
      optimizer_kwargs:
        smac_facade:
          _target_: smac.facade.HyperparameterOptimizationFacade
          _partial_: true
          logging_level: 20
        scenario:
          seed: ${seed}
          n_trials: ${hydra.sweeper.n_trials}
          deterministic: false
          n_workers: 1
          output_directory: ${hydra.sweep.dir}
    search_space: ${search_space}
  run:
    dir: outputs/${agent}/${now:%Y-%m-%d_%H-%M-%S}
  sweep:
    dir: outputs/${agent}_sweep/${now:%Y-%m-%d_%H-%M-%S}
